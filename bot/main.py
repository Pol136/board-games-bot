import random
import pickle
import json
import nltk
import warnings

from text_utils import clean_and_lemmatize
from bot_config import BOT_CONFIG
from wikipedia_search import search_in_wikipedia, wants_wikipedia

warnings.filterwarnings("ignore", category=UserWarning)


nltk.download('punkt')


# --- –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ ---
with open('intent_model.pkl', 'rb') as f:
    clf = pickle.load(f)

with open('vectorizer.pkl', 'rb') as f:
    vectorizer = pickle.load(f)

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∏–∞–ª–æ–≥–æ–≤ ---
with open('cleaned_dialogues.json', encoding='utf-8') as f:
    dataset = json.load(f)
    # dataset = random.sample(dataset, 1000)

# def clean_text(text):
#     alphabet = ' –∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è-1234567890'
#     return ''.join(ch for ch in text.lower() if ch in alphabet)

# --- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –∏–∑ –¥–∏–∞–ª–æ–≥–æ–≤ ---
def get_generative_answer(text):
    text = clean_and_lemmatize(text)
    candidates = []

    for question, answer in dataset:
        if abs(len(text) - len(question)) / len(question) < 0.2:
            dist = nltk.edit_distance(text, question)
            if dist / len(question) < 0.3:
                candidates.append((dist, answer))

    if candidates:
        return min(candidates, key=lambda x: x[0])[1]

# --- ML-–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞–º–µ—Ä–µ–Ω–∏—è ---
def get_intent_ml(text):
    lemmatized = clean_and_lemmatize(text)
    text_vector = vectorizer.transform([lemmatized])
    return clf.predict(text_vector)[0]

# --- –û—Ç–≤–µ—Ç –ø–æ –Ω–∞–º–µ—Ä–µ–Ω–∏—é ---
def get_answer_by_intent(intent):
    return random.choice(BOT_CONFIG['intents'][intent]['responses'])

# --- –§—Ä–∞–∑–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é ---
def get_failure_phrase():
    return random.choice(BOT_CONFIG['failure_phrases'])

# --- –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –±–æ—Ç–∞ ---
def bot(text):
    try:
        # 1. –ï—Å–ª–∏ —è–≤–Ω–æ –ø—Ä–æ—Å–∏—Ç –í–∏–∫–∏–ø–µ–¥–∏—é
        if wants_wikipedia(text):
            wiki = search_in_wikipedia(text)
            if wiki:
                return wiki
            return "–Ø –Ω–µ –Ω–∞—à—ë–ª –ø–æ–¥—Ö–æ–¥—è—â—É—é —Å—Ç–∞—Ç—å—é –≤ –í–∏–∫–∏–ø–µ–¥–∏–∏ üòï"

        # 2. –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞–º–µ—Ä–µ–Ω–∏—è
        intent = get_intent_ml(text)
        if intent:
            return get_answer_by_intent(intent)

        # 3. –ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–π –æ—Ç–≤–µ—Ç
        answer = get_generative_answer(text)
        if answer:
            return answer

        return get_failure_phrase()
    except Exception as e:
        print("–û—à–∏–±–∫–∞:", e)
        return "–ß—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫..."


# --- –ö–æ–Ω—Å–æ–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ ---
if __name__ == '__main__':
    print("üé≤ –ì–µ–π–º–ë–æ—Ç –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ. –ü–∏—à–∏ —á—Ç–æ-–Ω–∏–±—É–¥—å:")
    while True:
        msg = input("> ")
        if msg.lower() in ['–≤—ã—Ö–æ–¥', 'exit', 'quit']:
            print("–ë–æ—Ç: –î–æ –≤—Å—Ç—Ä–µ—á–∏!")
            break
        print("–ë–æ—Ç:", bot(msg))
